# BLEnD Evaluation Configuration with VLLMInferenceEngine
# Example: MCQ evaluation for Algeria

experiment_name: blend_algeria_mcq

task:
  name: blend_cultural_knowledge
  type: blend
  config:
    blend_config: multiple-choice-questions  # or "short-answer-questions"
    culture: DZ  # See culture codes below
    use_english: true

# Model configuration (matches VLLMConfig)
model:
  name: meta-llama/Llama-3.2-3B-Instruct  # HuggingFace model name
  
  # vLLM Engine Configuration
  tensor_parallel_size: 1  # Number of GPUs to use
  gpu_memory_utilization: 0.9  # Fraction of GPU memory to use
  max_model_len: null  # Maximum sequence length (null for model default)
  trust_remote_code: true  # Trust remote code in model
  dtype: auto  # auto, half, float16, bfloat16, float, float32
  quantization: null  # awq, gptq, squeezellm, fp8
  swap_space: 4  # CPU swap space in GiB
  enforce_eager: false  # Disable CUDA graph
  max_num_seqs: 256  # Max sequences per iteration
  seed: 42  # Random seed
  
  # Generation Parameters
  temperature: 0.0  # 0 for deterministic
  max_tokens: 100  # Maximum tokens to generate
  top_p: 1.0  # Nucleus sampling
  top_k: -1  # Top-k sampling (-1 to disable)
  presence_penalty: 0.0  # Presence penalty
  frequency_penalty: 0.0  # Frequency penalty
  stop: null  # Stop sequences (e.g., ["\n\n", "END"])

evaluation:
  num_samples: 50  # -1 for all samples
  batch_size: 10


# Output settings
output:
  results_dir: results
  save_predictions: true
  verbose: true

